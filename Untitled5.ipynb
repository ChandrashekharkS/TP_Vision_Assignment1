{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733ea84a-971f-4f44-8d19-b05adf8e47f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa93a2f82ad14cbe9eeb502a10e4b437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/935 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dell\\.cache\\huggingface\\hub\\models--bhadresh-savani--bert-base-uncased-emotion. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b27e0053244b8aa655a5cb37426eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79ef2e16a5b49ecbab39e5a54d8402b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9b7a77796c4674a9769bc5ce14e57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bc351944534759b9fcb30f09b342b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c5c7804dde4a02aaee197f09c5d9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training and saving completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import pickle\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"LDJnr/Puffin\")\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Extract human messages from conversations\n",
    "def extract_human_messages(conversations):\n",
    "    if isinstance(conversations, str):\n",
    "        conversations = ast.literal_eval(conversations)\n",
    "    return \" \".join([msg['value'] for msg in conversations if msg['from'] == 'human'])\n",
    "\n",
    "df['human_messages'] = df['conversations'].apply(extract_human_messages)\n",
    "\n",
    "# Generate embeddings using a SentenceTransformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(df['human_messages'].tolist())\n",
    "\n",
    "# Perform KMeans clustering with 2 clusters\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "df['topic'] = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Assign topic labels\n",
    "topic_labels = {0: \"Programming Practices\", 1: \"Misc\"}\n",
    "\n",
    "# Determine which cluster represents \"Programming Practices\"\n",
    "cluster_meanings = {}\n",
    "for cluster_id in range(2):\n",
    "    sample_texts = df[df['topic'] == cluster_id]['human_messages'].head(10)\n",
    "    if any(\"code\" in text.lower() or \"programming\" in text.lower() or \"app\" in text.lower() for text in sample_texts):\n",
    "        cluster_meanings[cluster_id] = \"Programming Practices\"\n",
    "    else:\n",
    "        cluster_meanings[cluster_id] = \"Misc\"\n",
    "\n",
    "# Map the identified labels to the clusters\n",
    "df['topic_label'] = df['topic'].map(cluster_meanings)\n",
    "\n",
    "# Sentiment Analysis: Use a model with three classes (positive, neutral, negative)\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"bhadresh-savani/bert-base-uncased-emotion\")\n",
    "\n",
    "# Analyze sentiments\n",
    "def analyze_sentiment(message):\n",
    "    sentiment_result = sentiment_analyzer(message[:512])[0]\n",
    "    return sentiment_result['label']\n",
    "\n",
    "df['sentiment'] = df['human_messages'].apply(analyze_sentiment)\n",
    "\n",
    "# Save the trained models and mappings\n",
    "with open('topic_model.pkl', 'wb') as f:\n",
    "    pickle.dump(kmeans, f)\n",
    "\n",
    "with open('topic_labels.pkl', 'wb') as f:\n",
    "    pickle.dump(cluster_meanings, f)\n",
    "\n",
    "with open('sentence_transformer.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Model training and saving completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343ff85-f325-4bd7-9d8d-f452b60c0e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
